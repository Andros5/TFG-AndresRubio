{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concepts import Context as BaseContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context(BaseContext):\n",
    "    def __init__(self, objetos, atributos, bools, confianza=0.85, soporte=32/712):\n",
    "        super().__init__(objetos, atributos, bools)\n",
    "        self.confianza = confianza\n",
    "        self.soporte = soporte\n",
    "        self.base_stem = None\n",
    "        self.base_luxenburger = None\n",
    "        self.base_completa = None\n",
    "\n",
    "    @classmethod\n",
    "    def desde_dataframe(cls, df, confianza=0.85, soporte=32/712):\n",
    "        # Eliminar la primera columna del dataframe df que corresponde al id\n",
    "        df = df.iloc[:, 1:]\n",
    "        objetos = list(df.index.astype(str))\n",
    "        atributos = list(df.columns.astype(str))\n",
    "        bools = [tuple(bool(x) for x in fila) for fila in df.values]\n",
    "        return cls(objetos, atributos, bools, confianza, soporte)\n",
    "\n",
    "\n",
    "    def set_confianza(self, confianza):\n",
    "        \"\"\"Establece el valor del hiperparámetro confianza.\"\"\"\n",
    "        self.confianza = confianza\n",
    "\n",
    "    def get_confianza(self):\n",
    "        \"\"\"Obtiene el valor del hiperparámetro confianza.\"\"\"\n",
    "        return self.confianza\n",
    "\n",
    "    def set_soporte(self, soporte):\n",
    "        \"\"\"Establece el valor del hiperparámetro soporte.\"\"\"\n",
    "        self.soporte = soporte\n",
    "\n",
    "    def get_soporte(self):\n",
    "        \"\"\"Obtiene el valor del hiperparámetro soporte.\"\"\"\n",
    "        return self.soporte\n",
    "    \n",
    "    def cerrar(self, conj, impls):\n",
    "        \"\"\"Cierra un conjunto de atributos usando la base de implicaciones de entrada.\"\"\"\n",
    "        cerrado = set(conj)\n",
    "        cambios = True\n",
    "        while cambios:\n",
    "            cambios = False\n",
    "            for impl,_,_ in impls:\n",
    "                if impl[0].issubset(cerrado) and not impl[1].issubset(cerrado):\n",
    "                    cerrado.update(impl[1])\n",
    "                    cambios = True\n",
    "        return cerrado\n",
    "\n",
    "    def next_closure(self, conjunto, conj_impls):\n",
    "        \"\"\"Calcula el siguiente cierre de un conjunto de atributos.\"\"\"\n",
    "        rev_set_prop=sorted(self.properties, reverse=True)\n",
    "        for atributo in rev_set_prop:\n",
    "            if atributo in conjunto:\n",
    "                conjunto=conjunto - {atributo}\n",
    "            else:\n",
    "                sig_conj_cerrado=self.cerrar(conjunto | {atributo}, conj_impls)\n",
    "                if all(x >= atributo for x in sig_conj_cerrado - conjunto):\n",
    "                    return sig_conj_cerrado\n",
    "        return None\n",
    "    \n",
    "    def doble_derivada(self, conjunto):\n",
    "        \"\"\"Calcula la doble derivada de un conjunto de atributos.\"\"\"\n",
    "        conjunto2 = set(conjunto)\n",
    "        return set(self.intension(self.extension(conjunto2)))\n",
    "\n",
    "    def calcular_base_stem(self):\n",
    "        \"\"\"Calcula la base Stem de un contexto como lista de tuplas.\"\"\"\n",
    "        conj_atrib=set()\n",
    "        base=[]\n",
    "        atributos=set(self.properties)\n",
    "        while conj_atrib!=atributos and conj_atrib!= None:\n",
    "            conj_atrib_pp=self.doble_derivada(conj_atrib)\n",
    "            if conj_atrib != conj_atrib_pp:\n",
    "                implicacion = (conj_atrib, conj_atrib_pp - conj_atrib)\n",
    "                base.append((implicacion, 1., self.soporte_implicacion(implicacion)))\n",
    "            conj_atrib = self.next_closure(conj_atrib, base)\n",
    "        self.base_stem = base\n",
    "        return base\n",
    "\n",
    "    def es_cerrado(self, conjunto):\n",
    "        \"\"\"Determina si un conjunto de atributos es cerrado en un contexto formal.\"\"\"\n",
    "        return conjunto == set(self.intension(self.extension(conjunto)))\n",
    "\n",
    "    def soporte_atributos(self, conjunto):\n",
    "        \"\"\"Calcula el soporte de un conjunto de atributos en un contexto formal.\"\"\"\n",
    "        numerador = len(self.extension(conjunto))  # |A'|\n",
    "        denominador = len(self.objects)  # |O|\n",
    "        return numerador / denominador\n",
    "\n",
    "    def soporte_concepto(self, concepto):\n",
    "        \"\"\"Calcula el soporte de un concepto en un contexto formal.\"\"\"\n",
    "        extension, _ = concepto\n",
    "        numerador = len(extension)\n",
    "        denominador = len(self.objects)\n",
    "        return numerador / denominador\n",
    "\n",
    "    def sigma_frecuente(self, concepto, sigma):\n",
    "        \"\"\"Determina si un concepto es frecuente en un contexto formal.\"\"\"\n",
    "        return self.soporte_concepto(concepto) >= sigma\n",
    "\n",
    "    def es_inmediatamente_inferior(self, Y1, Y2):\n",
    "        \"\"\"Determina, por medio de sus conjuntos de atributos, si un concepto es inmediatamente inferior a otro en un contexto formal.\"\"\"\n",
    "        if Y1 == Y2:  # Si los conjuntos de atributos son iguales, no son inmediatamente inferiores\n",
    "            return False\n",
    "        if not Y1.issubset(Y2):  # Si Y1 no es subconjunto de Y2, no son inmediatamente inferiores\n",
    "            return False\n",
    "        if not self.es_cerrado(Y1) or not self.es_cerrado(Y2):  # Si alguno de los conjuntos de atributos no es cerrado, no son inmediatamente inferiores\n",
    "            return False\n",
    "        extension1 = self.extension(Y1)\n",
    "        extension2 = self.extension(Y2)\n",
    "        vecinos = [(set(extension), set(intension)) for extension, intension in self.neighbors(extension2)]\n",
    "        conceptoY1 = (set(extension1), Y1)\n",
    "        if conceptoY1 in vecinos:  # Si el concepto (A', Y1) está en los vecinos de (A'', Y2), entonces Y1 es inmediatamente inferior a Y2\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def soporte_implicacion(self, implicacion):\n",
    "        \"\"\"Calcula el soporte de una implicación en un contexto formal.\"\"\"\n",
    "        antecedente, consecuente = implicacion\n",
    "        numerador = len(self.extension(antecedente | consecuente))  # |(Y1 ∪ Y2)'|\n",
    "        denominador = len(self.objects)  # |O|\n",
    "        return numerador / denominador\n",
    "\n",
    "    def confianza_implicacion(self, implicacion):\n",
    "        \"\"\"Calcula la confianza de una implicación en un contexto formal.\"\"\"\n",
    "        antecedente, consecuente = implicacion\n",
    "        numerador = len(self.extension(antecedente | consecuente))  # |(Y1 ∪ Y2)'|\n",
    "        denominador = len(self.extension(antecedente))  # |Y1'|\n",
    "        if denominador == 0:\n",
    "            return 1.0\n",
    "        return numerador / denominador\n",
    "\n",
    "    def calcular_base_luxenburger(self):\n",
    "        \"\"\"Calcula la base de Luxenburger de un contexto formal como lista de tuplas de conjuntos de atributos.\"\"\"\n",
    "        base_luxenburger = []\n",
    "        visitados = set()\n",
    "        reticulo = self.lattice\n",
    "        n = len(self.objects)\n",
    "        def aux_base_luxenburger(concepto_actual):\n",
    "            \"\"\"Auxiliar para recorrer cada nodo del reticulo del contexto formal de arriba a abajo.\"\"\"\n",
    "            if concepto_actual in visitados: # Si el concepto actual ya fue visitado, no hacer nada\n",
    "                return\n",
    "            visitados.add(concepto_actual)\n",
    "            for vecino in concepto_actual.lower_neighbors: # Recorrer los vecinos inferiores del concepto actual\n",
    "                intencion_vecino = set(vecino.intent)\n",
    "                intencion_actual = set(concepto_actual.intent)\n",
    "                implicacion = (intencion_actual, intencion_vecino - intencion_actual) # Representa la implicacion Act -> Vec\\Act\n",
    "                num_objetos_actual = len(concepto_actual.extent)\n",
    "                if num_objetos_actual != 0:\n",
    "                    conf_Implicacion = len(vecino.extent)/num_objetos_actual\n",
    "                else:\n",
    "                    conf_Implicacion = 0.\n",
    "                sop_Implicacion = len(vecino.extent)/n\n",
    "                if sop_Implicacion >= self.soporte and conf_Implicacion >= self.confianza: # Si la implicacion es frecuente, agregarla a la base de Luxenburger\n",
    "                    base_luxenburger.append((implicacion, conf_Implicacion, sop_Implicacion))\n",
    "                elif sop_Implicacion < self.soporte: # Realizar la poda si el soporte es menor al umbral\n",
    "                    return\n",
    "                aux_base_luxenburger(vecino)\n",
    "        aux_base_luxenburger(reticulo[len(reticulo)-1]) # Comenzar desde el concepto superior del reticulo\n",
    "        self.base_luxenburger = base_luxenburger\n",
    "        return base_luxenburger\n",
    "    \n",
    "    def calcular_base_completa(self):\n",
    "        \"\"\"Calcula la base completa como la union de la base Stem y de Luxenburger.\"\"\"\n",
    "        if self.base_stem is None:\n",
    "            raise Exception(\"Primero debe calcular la base Stem.\")\n",
    "        if self.base_luxenburger is None:\n",
    "            raise Exception(\"Primero debe calcular la base de Luxenburger.\")\n",
    "\n",
    "        base_completa = self.base_stem.copy()\n",
    "        base_completa.extend(self.base_luxenburger)\n",
    "        self.base_completa = base_completa\n",
    "        return base_completa\n",
    "    \n",
    "    def cerrar_conjunto(self, conjunto):\n",
    "        \"\"\"Dado un conjunto de atributos y la base de implicaciones, devuelve el conjunto cerrado.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base completa.\")\n",
    "        cerrado = set(conjunto)\n",
    "        implicaciones = []\n",
    "        \n",
    "        for implicacion,_,_ in self.base_completa:\n",
    "            if implicacion[0].issubset(cerrado):\n",
    "                cerrado.update(implicacion[1])\n",
    "                implicaciones.append(implicacion)\n",
    "        return cerrado, implicaciones\n",
    "    \n",
    "    def entrenar(self):\n",
    "        \"\"\"Calcula todas las bases de un contexto formal.\"\"\"\n",
    "        self.calcular_base_stem()\n",
    "        self.calcular_base_luxenburger()\n",
    "        self.calcular_base_completa()\n",
    "    \n",
    "    def predecir(self, datos):\n",
    "        \"\"\"Predice las etiquetas de un dataframe de Xs y vacios aplicando el metodo XAI de la base completa.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base completa.\")\n",
    "        etiquetas = []\n",
    "        datos.drop(columns=[\"Survived\"], inplace=True, errors='ignore')\n",
    "        for i in range(len(datos)):\n",
    "            instancia = datos.iloc[i]\n",
    "            conjunto = set(datos.columns[1:][instancia.iloc[1:] == \"X\"])\n",
    "            cerrado, implicaciones = self.cerrar_conjunto(conjunto)\n",
    "            ''' ESTO SE DESCOMENTA Y SE COMENTA EL IF DE ABAJO PARA PROBARLO SIN EL ATRIBUTO NOTSURVIVED\n",
    "            if \"Survived\" in cerrado:\n",
    "                etiquetas.append(\"X\")\n",
    "            else:\n",
    "                etiquetas.append(\"\")\n",
    "            '''\n",
    "            \n",
    "            if \"Survived\" in cerrado and \"NotSurvived\" in cerrado:\n",
    "                maximo = max(implicaciones, key=lambda x: x[1])\n",
    "                if \"Survived\" in maximo[1] and \"NotSurvived\" not in maximo[1]:\n",
    "                    etiquetas.append(\"X\")\n",
    "                elif \"NotSurvived\" in maximo[1] and \"Survived\" not in maximo[1]:\n",
    "                    etiquetas.append(\"\")\n",
    "                else:\n",
    "                    etiquetas.append(\"X\")\n",
    "            elif \"Survived\" in cerrado:\n",
    "                etiquetas.append(\"X\")\n",
    "            else:\n",
    "                etiquetas.append(\"\")\n",
    "            \n",
    "        return pd.Series(etiquetas, index=datos.index, name=\"Survived\")\n",
    "    \n",
    "    def precision(self, datos, etiquetas):\n",
    "        \"\"\"Calcula la precisión de un dataframe de Xs y vacios con sus etiquetas aplicando el metodo XAI de la base completa.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base de Luxenburger.\")\n",
    "        predicciones = self.predecir(datos)\n",
    "        coincidencias = predicciones == etiquetas\n",
    "        return coincidencias.mean()\n",
    "    \n",
    "    def falsos_positivos(self, datos, etiquetas):\n",
    "        \"\"\"Calcula la cantidad de falsos positivos de un dataframe de datos con sus etiquetas aplicando el metodo XAI de la base completa.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base completa.\")\n",
    "        predicciones = self.predecir(datos)\n",
    "        falsos_positivos = ((predicciones == \"X\") & (etiquetas == \"\")).sum()\n",
    "        return falsos_positivos\n",
    "    \n",
    "    def falsos_negativos(self, datos, etiquetas):\n",
    "        \"\"\"Calcula la cantidad de falsos negativos de un dataframe de datos con sus etiquetas aplicando el metodo XAI de la base completa.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base completa.\")\n",
    "        predicciones = self.predecir(datos)\n",
    "        falsos_negativos = ((predicciones == \"\") & (etiquetas == \"X\")).sum()\n",
    "        return falsos_negativos\n",
    "    \n",
    "    def calcula_resultados(self, datos, etiquetas):\n",
    "        \"\"\"Calcula la precisión, falsos positivos y falsos negativos de un dataframe de datos con sus etiquetas aplicando el metodo XAI de la base completa.\"\"\"\n",
    "        if self.base_completa is None:\n",
    "            raise Exception(\"Primero debe calcular la base completa.\")\n",
    "        predicciones = self.predecir(datos)\n",
    "        coincidencias = predicciones == etiquetas\n",
    "        falsos_positivos = ((predicciones == \"X\") & (etiquetas == \"\")).sum()\n",
    "        falsos_negativos = ((predicciones == \"\") & (etiquetas == \"X\")).sum()\n",
    "        return coincidencias.mean(), falsos_positivos, falsos_negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset del Titanic\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores nulos con el valor más frecuente\n",
    "data.loc[:, 'Sex'] = data['Sex'].fillna(data['Sex'].mode()[0])\n",
    "data.loc[:, 'Age'] = data['Age'].fillna(data['Age'].median())\n",
    "data.loc[:, 'Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "data.loc[:, 'Pclass'] = data['Pclass'].fillna(data['Pclass'].mode()[0])\n",
    "data.loc[:, 'Fare'] = data['Fare'].fillna(data['Fare'].mean())\n",
    "data.loc[:, 'SibSp'] = data['SibSp'].fillna(data['SibSp'].mode()[0])\n",
    "data.loc[:, 'Parch'] = data['Parch'].fillna(data['Parch'].mode()[0])\n",
    "\n",
    "separacion_age = 4\n",
    "separacion_fare = 8    \n",
    "\n",
    "# Definir intervalos y etiquetas de edad\n",
    "age_bins = [i/separacion_age*81 for i in range(separacion_age+1)]\n",
    "age_labels = [f\"{int(age_bins[i])}-{int(age_bins[i+1])}\" for i in range(len(age_bins)-1)]\n",
    "# Crear una nueva columna con categorías de edad\n",
    "data[\"AgeGroup\"] = pd.cut(data[\"Age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de tarifa\n",
    "fare_bins = [i/separacion_fare*513 for i in range(separacion_fare+1)]\n",
    "fare_labels = [f\"{int(fare_bins[i])}-{int(fare_bins[i+1])}\" for i in range(len(fare_bins)-1)]\n",
    "\n",
    "# Crear una nueva columna con categorías de tarifa\n",
    "data[\"FareGroup\"] = pd.cut(data[\"Fare\"], bins=fare_bins, labels=fare_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de SibSp\n",
    "sibsp_bins = [0, 1, 3, 5, 7, float('inf')]\n",
    "sibsp_labels = [\"0-1\", \"1-3\", \"3-5\", \"5-7\", \"7+\"]\n",
    "\n",
    "# Crear una nueva columna con categorías de SibSp\n",
    "data[\"SibSpGroup\"] = pd.cut(data[\"SibSp\"], bins=sibsp_bins, labels=sibsp_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de Parch\n",
    "parch_bins = [0, 1, 3, 5,float('inf')]\n",
    "parch_labels = [\"0-1\", \"1-3\", \"3-5\", \"5+\"]\n",
    "\n",
    "# Crear una nueva columna con categorías de Parch\n",
    "data[\"ParchGroup\"] = pd.cut(data[\"Parch\"], bins=parch_bins, labels=parch_labels, right=False)\n",
    "\n",
    "# Convertir a codificación one-hot (columnas 1/0)\n",
    "data = pd.get_dummies(data, columns=[\"FareGroup\", \"AgeGroup\", \"Embarked\", \"Pclass\", \"SibSpGroup\", \"ParchGroup\"], dtype=int, drop_first=False)\n",
    "\n",
    "# Convertir columnas a 1/0\n",
    "data['Male'] = data['Sex'].map({'male': 1, 'female': 0})\n",
    "data['Female'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Añadir una columna que sea la contraria de la columna 'Survived'\n",
    "'''ESTO SE COMENTARIA SI NO SE VA A USAR EL ATRIBUTO NOTSURVIVED'''\n",
    "data['NotSurvived'] = data['Survived'].map({0: 1, 1: 0})\n",
    "\n",
    "# Eliminar las columnas inútiles\n",
    "data.drop(['Age', 'Sex', 'Fare', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "# Convertir selectivamente columnas a tipo string antes de reemplazar 1 con 'X'\n",
    "columns_to_convert = data.columns[1:]\n",
    "data[columns_to_convert] = data[columns_to_convert].astype(str).map(lambda x: 'X' if x == '1' else '')\n",
    "\n",
    "# Mostrar los nombres de las columnas\n",
    "#print(\"Nombres de las columnas:\", data.columns)\n",
    "\n",
    "# Guardar el resultado final en un archivo CSV\n",
    "data.to_csv(\"trainDummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Pclass                                          Name     Sex  \\\n",
      "PassengerId                                                                 \n",
      "892               3                              Kelly, Mr. James    male   \n",
      "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "894               2                     Myles, Mr. Thomas Francis    male   \n",
      "895               3                              Wirz, Mr. Albert    male   \n",
      "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "PassengerId                                                       \n",
      "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
      "893          47.0      1      0   363272   7.0000   NaN        S  \n",
      "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
      "895          27.0      0      0   315154   8.6625   NaN        S  \n",
      "896          22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "test_sub = pd.read_csv(\"test.csv\", index_col=\"PassengerId\")\n",
    "print(test_sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores nulos con el valor más frecuente\n",
    "test_sub.loc[:, 'Sex'] = test_sub['Sex'].fillna(test_sub['Sex'].mode()[0])\n",
    "test_sub.loc[:, 'Age'] = test_sub['Age'].fillna(test_sub['Age'].median())\n",
    "test_sub.loc[:, 'Embarked'] = test_sub['Embarked'].fillna(test_sub['Embarked'].mode()[0])\n",
    "test_sub.loc[:, 'Pclass'] = test_sub['Pclass'].fillna(test_sub['Pclass'].mode()[0])\n",
    "test_sub.loc[:, 'Fare'] = test_sub['Fare'].fillna(test_sub['Fare'].mean())\n",
    "test_sub.loc[:, 'SibSp'] = test_sub['SibSp'].fillna(test_sub['SibSp'].mode()[0])\n",
    "test_sub.loc[:, 'Parch'] = test_sub['Parch'].fillna(test_sub['Parch'].mode()[0])\n",
    "\n",
    "separacion_age = 4\n",
    "separacion_fare = 8    \n",
    "\n",
    "# Definir intervalos y etiquetas de edad\n",
    "age_bins = [i/separacion_age*81 for i in range(separacion_age+1)]\n",
    "age_labels = [f\"{int(age_bins[i])}-{int(age_bins[i+1])}\" for i in range(len(age_bins)-1)]\n",
    "# Crear una nueva columna con categorías de edad\n",
    "test_sub[\"AgeGroup\"] = pd.cut(test_sub[\"Age\"], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de tarifa\n",
    "fare_bins = [i/separacion_fare*513 for i in range(separacion_fare+1)]\n",
    "fare_labels = [f\"{int(fare_bins[i])}-{int(fare_bins[i+1])}\" for i in range(len(fare_bins)-1)]\n",
    "\n",
    "# Crear una nueva columna con categorías de tarifa\n",
    "test_sub[\"FareGroup\"] = pd.cut(test_sub[\"Fare\"], bins=fare_bins, labels=fare_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de SibSp\n",
    "sibsp_bins = [0, 1, 3, 5, 7, float('inf')]\n",
    "sibsp_labels = [\"0-1\", \"1-3\", \"3-5\", \"5-7\", \"7+\"]\n",
    "\n",
    "# Crear una nueva columna con categorías de SibSp\n",
    "test_sub[\"SibSpGroup\"] = pd.cut(test_sub[\"SibSp\"], bins=sibsp_bins, labels=sibsp_labels, right=False)\n",
    "\n",
    "# Definir intervalos y etiquetas de Parch\n",
    "parch_bins = [0, 1, 3, 5,float('inf')]\n",
    "parch_labels = [\"0-1\", \"1-3\", \"3-5\", \"5+\"]\n",
    "\n",
    "# Crear una nueva columna con categorías de Parch\n",
    "test_sub[\"ParchGroup\"] = pd.cut(test_sub[\"Parch\"], bins=parch_bins, labels=parch_labels, right=False)\n",
    "\n",
    "# Convertir a codificación one-hot (columnas 1/0)\n",
    "test_sub = pd.get_dummies(test_sub, columns=[\"FareGroup\", \"AgeGroup\", \"Embarked\", \"Pclass\", \"SibSpGroup\", \"ParchGroup\"], dtype=int, drop_first=False)\n",
    "\n",
    "# Convertir columnas a 1/0\n",
    "test_sub['Male'] = test_sub['Sex'].map({'male': 1, 'female': 0})\n",
    "test_sub['Female'] = test_sub['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Añadir una columna que sea la contraria de la columna 'Survived'\n",
    "#data['NotSurvived'] = data['Survived'].map({0: 1, 1: 0})\n",
    "\n",
    "# Eliminar las columnas inútiles\n",
    "test_sub.drop(['Age', 'Sex', 'Fare', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
    "\n",
    "# Convertir selectivamente columnas a tipo string antes de reemplazar 1 con 'X'\n",
    "columns_to_convert = test_sub.columns[1:]\n",
    "test_sub[columns_to_convert] = test_sub[columns_to_convert].astype(str).map(lambda x: 'X' if x == '1' else '')\n",
    "\n",
    "# Mostrar los nombres de las columnas\n",
    "#print(\"Nombres de las columnas:\", data.columns)\n",
    "\n",
    "# Guardar el resultado final en un archivo CSV\n",
    "test_sub.to_csv(\"testDummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context3=Context.fromfile('trainDummy.csv', frmat='csv')\n",
    "context3.set_confianza(0.80)\n",
    "context3.set_soporte(16/712)\n",
    "context3.calcular_base_stem()\n",
    "context3.calcular_base_luxenburger()\n",
    "context3.calcular_base_completa()\n",
    "# Aplicamos filtrado del capitulo 5 y además hacemos las modificaciones tras añadir el atributo objetivo negado\n",
    "context3.base_completa = [i for i in context3.base_completa if i[2] >= 16/712 and 'Survived' not in i[0][0] and 'NotSurvived' not in i[0][0] and ('Survived' in i[0][1] or 'NotSurvived' in i[0][1])]\n",
    "'''LO ANTERIOR SE COMENTA Y LO SIGUIENTE SE DESCOMENTA PARA TRABAJAR CON EL ATRIBUTO NOTSURVIVED'''\n",
    "#context3.base_completa = [i for i in context3.base_completa if i[2] >= 16/712 and 'Survived' not in i[0][0] and 'Survived' in i[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = context3.predecir(test_sub)\n",
    "predicciones = predicciones.apply(lambda x: 1 if str(x).strip().upper() == \"X\" else 0)\n",
    "predicciones.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
