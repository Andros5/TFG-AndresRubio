# TFG - Andr√©s Rubio

Este repositorio contiene el c√≥digo, datos y resultados desarrollados para el Trabajo Fin de Grado (TFG) titulado **"An√°lisis Formal de Conceptos como Herramienta para la Explicabilidad en Modelos de Aprendizaje Autom√°tico"**.

El objetivo del TFG es aplicar t√©cnicas del **An√°lisis Formal de Conceptos (AFC)** para la **extracci√≥n y uso de implicaciones l√≥gicas** en conjuntos de datos, con √©nfasis en la explicabilidad de decisiones autom√°ticas. Se analiza el comportamiento de dichas implicaciones en distintos contextos, centr√°ndose especialmente en c√≥mo var√≠an los resultados al ajustar par√°metros como el soporte y la confianza.

Se utilizan dos conjuntos de datos reales: el conocido dataset **Titanic** y el dataset de **Churn Modelling** (fuga de clientes). Ambos han sido discretizados y tratados para permitir la generaci√≥n de implicaciones a trav√©s de herramientas como **ConExp** y el an√°lisis de su impacto en predicciones.

---

## üîß Estructura del repositorio

Este repositorio se divide en dos carpetas principales:

- [`titanic/`](#-titanic)
- [`churn_modelling/`](#-churn-modelling)

---

## üìÅ Titanic

Contiene todos los notebooks, datos y resultados relacionados con el an√°lisis basado en el dataset Titanic.

### Archivos principales:

- **`ajusteHiperparametrosModeloXAI.ipynb`**  
  Notebook encargado del ajuste de hiperpar√°metros como soporte, confianza, n√∫mero de rangos de edad y de tarifa. Relacionado con el **cap√≠tulo 5, secci√≥n 4** de la memoria.

- **`entregaKaggleModeloXAI.ipynb`**  
  Notebook que genera el CSV de predicci√≥n para Kaggle. Contiene dos versiones del modelo:
  - Versi√≥n cl√°sica utilizada en el **cap√≠tulo 5, secci√≥n 3**, con un **accuracy de 0.75598**.
  - Segunda versi√≥n alternativa (no incluida en la memoria) basada en comparar la **confianza de las implicaciones de `Survives` vs. `NotSurvived`**, alcanzando un **accuracy de 0.77511**.

- **`modeloXAI.ipynb`**  
  Modelo base empleado para los c√°lculos y predicciones. Utilizado en el **cap√≠tulo 4**, en las primeras secciones del **cap√≠tulo 5** y durante todo el **cap√≠tulo 6**. Es el modelo de referencia para hacer pruebas y generar nuevos resultados.

- **`resultados.txt`**  
  Registro de pruebas intermedias y anotaciones realizadas durante la fase de desarrollo del modelo antes de consolidar los resultados en la memoria final.

### Carpetas:

- **`conjuntos_entrenamiento/`**  
  Contiene variaciones y discretizaciones del conjunto de entrenamiento original en formato CSV. Se usaron para probar distintos cortes de edad y tarifa.

- **`conjuntos_prueba/`**  
  Contiene conjuntos de prueba discretizados, compatibles con los entrenamientos generados.

- **`resultados/`**  
  Archivos con resultados de implicaciones, predicciones y an√°lisis diversos generados durante los experimentos descritos en la memoria.

- **`titanic.zip`**  
  ZIP descargado desde Kaggle con los datasets `train.csv` y `test.csv` originales.

---

## üìÅ Churn Modelling

Conjunto de experimentos realizados sobre el dataset de fuga de clientes, aplicando tambi√©n el enfoque AFC.

### Archivos principales:

- **`churnModellingNotebook.ipynb`**  
  Notebook que utiliza las implicaciones generadas por **ConExp** y las adapta a una estructura de an√°lisis definida en la clase `Context` (descrita en la memoria). Se realizan c√°lculos sobre:
  - Frecuencia de implicaciones.
  - Falsos positivos y falsos negativos.
  - Variaciones seg√∫n umbrales de **confianza y soporte**.

- **`pasarAConExp.py`**  
  Script en Python para transformar datasets discretizados en formato `.cxt`, el cual es requerido por ConExp para generar las implicaciones.

### Carpetas:

- **`ConExpDatos/`**  
  - `.cxt`: contexto en formato formal para ConExp generado desde el conjunto de entrenamiento.  
  - `.txt`: archivo con todas las implicaciones generadas por ConExp desde el `.cxt`.

- **`conjuntos_entrenamiento/`**  
  Variaciones discretizadas del conjunto de entrenamiento de 8000 instancias.

- **`conjuntos_prueba/`**  
  Variaciones discretizadas del conjunto de prueba.

- **`resultados/`**  
  Resultados de an√°lisis similares a los realizados con el dataset Titanic.

- **`churn_modelling_dataset.zip`**  
  Contiene el CSV original con 1000 registros descargados desde Kaggle.

---

## üìö Tecnolog√≠as y herramientas utilizadas

- Python 3.10+
- Jupyter Notebooks
- ConExp (software para c√°lculo de implicaciones en AFC)
- Pandas, Numpy, Scikit-learn (preprocesamiento)
- Kaggle (datasets y evaluaci√≥n)
- Matplotlib, Seaborn (visualizaci√≥n de datos)

---

## üßæ Licencia

Este proyecto est√° licenciado bajo la **Licencia MIT**. Puedes consultarla en el archivo [`LICENSE`](./LICENSE) para m√°s detalles. Esto permite el uso, modificaci√≥n y distribuci√≥n del c√≥digo con fines acad√©micos o personales, siempre que se reconozca la autor√≠a original.

---

## ‚úâÔ∏è Contacto

Si tienes dudas sobre el contenido de este repositorio o el trabajo presentado, puedes contactarme a trav√©s de GitHub o mediante los datos de contacto proporcionados en la memoria del TFG.

---

## üîó Referencias

- [An√°lisis Formal de Conceptos - Wikipedia](https://es.wikipedia.org/wiki/An%C3%A1lisis_formal_de_conceptos)
- [ConExp - FCA Software Tool](https://conexp.github.io/)
- [Dataset Titanic - Kaggle](https://www.kaggle.com/c/titanic)
- [Dataset Churn Modelling - Kaggle](https://www.kaggle.com/datasets/shubhendra7/churn-modelling)

